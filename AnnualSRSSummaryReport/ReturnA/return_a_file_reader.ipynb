{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "967df8f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "import json \n",
    "import string\n",
    "import polars as pl \n",
    "import openpyxl as xl \n",
    "import shutil \n",
    "from datetime import datetime as dt \n",
    "here = os.path.abspath('')\n",
    "### set downloaded files directory: \n",
    "files_dir = os.path.join(here, 'SRSSummaryReport','YearlyData')\n",
    "files_dir = os.path.join(here, 'SRSSummaryReport','MonthlyData')\n",
    "### while parsing excel files - if the same county-month have been downloaded multiple times \n",
    "# it will not be duplicated in the final data set\n",
    "# duplicate files will be copied to this directory:\n",
    "dupe_files_dir = os.path.join(files_dir, 'Duplicates')\n",
    "### set output file destination \n",
    "output = os.path.join(here, f'SRSAnnualReturnAConsolidatedMonthlyData.xlsx')\n",
    "# output = os.path.join(here, f'SRSAnnualReturnAConsolidated.xlsx')\n",
    "print(dt.now())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74909b20",
   "metadata": {},
   "outputs": [],
   "source": [
    "files_to_read = []\n",
    "for root, dirs, files in os.walk(files_dir):\n",
    "    for fn, file in enumerate(files):\n",
    "        if file.endswith('.xlsx') and not file.startswith('~'): # and fn < 1:\n",
    "            file_path = os.path.join(root, file)\n",
    "            files_to_read.append(file_path)\n",
    "print(len(files_to_read), files_to_read)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76599c2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "### specific to the exported structure/format of the SRS Summary Report - Return A report when exported to Excel \n",
    "### Consolidate the individual county files into one dataset:\n",
    "### read each file into a dataframe, add the frame to a list of frames, concatenate all frames into 1\n",
    "file_frames = []\n",
    "# keeps track of county-time period files already loaded to manage duplicates\n",
    "load_keys = [] \n",
    "for fn, file_path in enumerate(files_to_read):\n",
    "    if os.path.exists(file_path):\n",
    "        ### load workbook and worksheet\n",
    "        wb = xl.load_workbook(file_path)\n",
    "        ws = wb.worksheets[0]\n",
    "        ### \n",
    "        begin = ws['d8'].value\n",
    "        begin_dt = begin[-10:]\n",
    "        end = ws['h9'].value\n",
    "        end_dt = end[-10:]\n",
    "        county = ws['b16'].value\n",
    "        county_name = county.replace(\"County: \",'')\n",
    "        # get printed on value from top right of report... report run date \n",
    "        report_run_date = ws['m3'].value\n",
    "        ### actual data table starts on b18 \n",
    "        table_start = 'b18'\n",
    "        load_key = f'{county}_{begin_dt}_{end_dt}'\n",
    "        if load_key not in load_keys:\n",
    "            # read the table starting with header row on row 17 (0 based index, Excel row 18)\n",
    "            df = pl.read_excel(file_path, read_options={'header_row':17}, infer_schema_length=0)\n",
    "            cols = df.columns \n",
    "            # manually add columns from the parameters above the table; \n",
    "            df = df.with_columns(\n",
    "                pl.lit(report_run_date).alias('ReportRunDate'),\n",
    "                pl.lit(file_path).alias('SourceFile'),\n",
    "                pl.lit(begin_dt ).alias('BeginDate'),\n",
    "                pl.lit(end_dt).alias('EndDate'),\n",
    "                pl.lit(county_name).alias('County')\n",
    "            )\n",
    "            # Re-order columns for cleanliness\n",
    "            order_cols = ['County','BeginDate','EndDate'] + cols + ['ReportRunDate','SourceFile']\n",
    "            df = df.select(order_cols)\n",
    "            file_frames.append(df)\n",
    "            print(fn, '/', len(files_to_read), begin_dt, end_dt, county_name, file)\n",
    "            load_keys.append(load_key)\n",
    "        else:\n",
    "            #move duplicate file and dont load:\n",
    "            move_dupe_file_to = os.path.join(dupe_files_dir, file)\n",
    "            shutil.move(file_path, move_dupe_file_to)\n",
    "            print(f'DUPLICATE: {load_key} moved to {move_dupe_file_to}')\n",
    "\n",
    "\n",
    "consolidated_df = pl.concat(file_frames)\n",
    "print(consolidated_df.shape)\n",
    "### distinct count of counties by begin date - validate all 67 are loaded for each time period\n",
    "with pl.Config(set_tbl_rows=48):\n",
    "    print(consolidated_df.group_by(['BeginDate']).agg(pl.col('County').n_unique()).sort('BeginDate'))\n",
    "print(dt.now().isoformat())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fed6748",
   "metadata": {},
   "outputs": [],
   "source": [
    "with pl.Config(set_tbl_rows=48):\n",
    "    print(consolidated_df.group_by(['BeginDate']).agg(pl.col('County').n_unique()).sort('BeginDate'))\n",
    "print(dt.now().isoformat())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8aee5501",
   "metadata": {},
   "outputs": [],
   "source": [
    "with pl.Config(set_tbl_cols=12):\n",
    "    print(consolidated_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf11cd50",
   "metadata": {},
   "outputs": [],
   "source": [
    "# consolidated_df = pl.read_excel(os.path.join(here, f'SRSAnnualReturnAConsolidated.xlsx'))\n",
    "\n",
    "### rename the default spreadsheet column names (removes line breaks in some column names)\n",
    "consolidated_columns_rename = [\n",
    "    'County',\n",
    "    'BeginDate',\n",
    "    'EndDate',\n",
    "    'Classification of Offenses',\n",
    "    'Offenses Reported',\n",
    "    'Unfounded',\n",
    "    'Actual Offenses',\n",
    "    'Total Offenses Cleared',\n",
    "    'Clearances Involving Persons Under 18 Yr. of Age',\n",
    "    'ReportRunDate',\n",
    "    'SourceFile',\n",
    "]\n",
    "consolidated_df.columns = consolidated_columns_rename\n",
    "\n",
    "### get county details sheet from ClassificationOfOffenses spreadsheet - pulling in county_fips_code for joining to census data\n",
    "## (used as a generic metadata/lookup/supplemental spreadsheet for this process - kept separate from the main consolidated SRS data file)\n",
    "lookup_xl = os.path.join(here, 'SRSSummaryReport', 'ClassificationOfOffenses.xlsx')\n",
    "county_df = pl.read_excel(lookup_xl, sheet_name='Counties')\n",
    "county_df = county_df.select(['County','county_fips_code'])\n",
    "county_df.columns = ['County Name','County FIPS Code']\n",
    "### merge county data with main data file to include county FIPS code with the main data - used to link up with census data \n",
    "consolidated_df = consolidated_df.join(county_df, left_on='County', right_on='County Name', how='left')\n",
    "\n",
    "consolidated_columns_after_join = [\n",
    "    'County',\n",
    "    'County FIPS Code',\n",
    "    'BeginDate',\n",
    "    'EndDate',\n",
    "    'Classification of Offenses',\n",
    "    'Offenses Reported',\n",
    "    'Unfounded',\n",
    "    'Actual Offenses',\n",
    "    'Total Offenses Cleared',\n",
    "    'Clearances Involving Persons Under 18 Yr. of Age',\n",
    "    'ReportRunDate',\n",
    "    'SourceFile',\n",
    "]\n",
    "consolidated_df = consolidated_df.select(consolidated_columns_after_join)\n",
    "\n",
    "### write excel with county fips code \n",
    "\n",
    "consolidated_df.write_excel(output)\n",
    "\n",
    "print(dt.now())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
